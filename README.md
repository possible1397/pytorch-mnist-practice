## 📘 專案說明（中文）

本專案使用 PyTorch 建立一個簡單的神經網路，用於辨識 MNIST 手寫數字影像。整體流程包含資料預處理、模型建立、訓練流程與結果評估。

---

### 🔁 程式碼流程解說

#### 1️⃣ 資料處理
透過 torchvision 套件下載 MNIST 資料集，並將影像轉為 tensor 格式後標準化，使模型更容易收斂。

#### 2️⃣ 建立模型
使用兩層全連接神經網路（MLP）：
- 輸入層將 28x28 的影像攤平成一維向量
- 中間層包含 ReLU 激活函數增加非線性能力
- 輸出層對應 0~9 共 10 個分類結果

#### 3️⃣ 模型訓練
訓練過程中：
- 每批資料進行 forward 預測
- 計算預測值與實際標籤的誤差（loss）
- 執行反向傳播更新權重
- 重複多個 epoch 不斷優化參數

#### 4️⃣ 測試與評估
將模型切換至評估模式後，在測試資料上計算預測結果並與標籤比較，得出整體準確率。

---

### 🧠 學習重點

- 熟悉神經網路的 forward → loss → backward → update 流程
- 了解 ReLU 如何讓模型具備非線性能力
- 學會使用 DataLoader 管理批次資料與訓練流程
- 初步掌握 PyTorch 架構與訓練基本技巧

## 🧠 CNN 模型補充說明

在本專案中，我將原本的 MLP 模型升級為卷積神經網路（CNN, Convolutional Neural Network），以提升對影像特徵的學習能力。

### 🔍 CNN 與 MLP 差異

- MLP 需要先將影像攤平成一維向量，容易喪失空間結構資訊。
- CNN 則能透過卷積操作保留局部空間特徵，例如邊緣、輪廓等。
- 通常 CNN 模型對影像分類任務表現更好，並具備更高的準確率與泛化能力。

### 📐 模型結構（簡略）

1. 兩層卷積層（Conv2d）搭配 ReLU 激活與 MaxPooling
2. 一層 Flatten 將特徵展平為一維向量
3. 兩層全連接層進行最終分類

### 📊 訓練結果

- 訓練輪數：5 epochs
- 測試集準確率：約 **97.88%**
- 效能明顯優於原本的 MLP 模型（約 94.5%）

### 🧠 學習重點（CNN）

- 學會使用 `nn.Conv2d`, `nn.MaxPool2d`, `nn.Sequential` 建構卷積模型
- 學會如何處理三維影像張量（batch_size × channel × height × width）
- 熟悉影像分類中常見的卷積流程與特徵萃取原理

> CNN 架構是影像處理與電腦視覺任務的核心工具，是我學習 PyTorch 中非常重要的一個里程碑。
> 
> ## 📂 檔案說明

| 檔名 | 用途 |
|------|------|
| `mnist_cnn_train.py` | 使用 CNN 模型訓練 MNIST 手寫數字分類任務，包含資料載入、模型定義、訓練流程與準確率評估，並將訓練結果儲存為 `model_cnn.pt` |
| `mnist_cnn_inference.py` | 載入已訓練的模型（`model_cnn.pt`），並對 MNIST 測試集中任一張圖片進行推論，顯示影像與預測結果 |
| `model_cnn.pt` | 訓練好的 CNN 模型權重檔案，可透過程式載入進行推論或接續訓練 |